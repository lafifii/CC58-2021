{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of EB_Topicos_ACT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1ab180b690ca4eafa9b3b8e05fa2d18c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TabModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "TabView",
            "_dom_classes": [],
            "_titles": {
              "0": "UPLOAD",
              "1": "DATASET",
              "2": "GREEDY/ENTROPIA",
              "3": "K2/ENTROPIA",
              "4": "GREEDY/K2",
              "5": "K2/K2",
              "6": "MAX/ENSAMBLE"
            },
            "_model_name": "TabModel",
            "_view_module": "@jupyter-widgets/controls",
            "selected_index": 0,
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9c7d70890a2447d0993703d613b1d29b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_de9b387ebe244dac91c370d25d5fec0b"
            ]
          }
        },
        "9c7d70890a2447d0993703d613b1d29b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "de9b387ebe244dac91c370d25d5fec0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a3adc8013cb24078af65b8975d657dd9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1c9f6f91ef864005b6b56669e2bb870e",
              "IPY_MODEL_9282b0e939ea44708e7eb7ad9ca44235"
            ]
          }
        },
        "a3adc8013cb24078af65b8975d657dd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1c9f6f91ef864005b6b56669e2bb870e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_73453a384e294dcfb0486dee0aa231f5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_956554c74917443e89f06a343f98e2b5",
              "IPY_MODEL_4dbf07f61bed47b695231f9408eac5da",
              "IPY_MODEL_eb6e5cf4f8a147ee9067ce5729339122"
            ]
          }
        },
        "9282b0e939ea44708e7eb7ad9ca44235": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ButtonView",
            "style": "IPY_MODEL_5962948827d14db486b90d28d648abe2",
            "_dom_classes": [],
            "description": "CREATE COMPONENTS",
            "_model_name": "ButtonModel",
            "button_style": "success",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "tooltip": "",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "layout": "IPY_MODEL_173c2d7156914bdeb55e1cec36a6efb7",
            "_model_module": "@jupyter-widgets/controls",
            "icon": "check"
          }
        },
        "73453a384e294dcfb0486dee0aa231f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "956554c74917443e89f06a343f98e2b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FileUploadModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "FileUploadView",
            "_counter": 0,
            "style": "IPY_MODEL_3d6bc3b2f08f4df6aa5d955c79966e6c",
            "_dom_classes": [],
            "description": "Select data.xlsx",
            "multiple": false,
            "_model_name": "FileUploadModel",
            "data": [
              null
            ],
            "button_style": "",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "accept": ".xlsx",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "error": "",
            "description_tooltip": null,
            "metadata": [
              {
                "name": "Comentarios.xlsx",
                "type": "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                "size": 131119,
                "lastModified": 1625700651683
              }
            ],
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_168e0a22ff5c4e6082f9a49470353e9b",
            "icon": "upload"
          }
        },
        "4dbf07f61bed47b695231f9408eac5da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ButtonView",
            "style": "IPY_MODEL_73683588e1a34288b4f80306cbc0057e",
            "_dom_classes": [],
            "description": "Upload DATASET",
            "_model_name": "ButtonModel",
            "button_style": "info",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "tooltip": "",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "layout": "IPY_MODEL_a90a474d7dd14bb78f2762d9c73ec278",
            "_model_module": "@jupyter-widgets/controls",
            "icon": "check"
          }
        },
        "eb6e5cf4f8a147ee9067ce5729339122": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "TextView",
            "style": "IPY_MODEL_a120817eb4c24ac0b54d9decf134184d",
            "_dom_classes": [],
            "description": "Cantidad a leer:",
            "_model_name": "TextModel",
            "placeholder": "Cantidad a leer",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "50",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "continuous_update": true,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e8f0d0ef466f4bc1bc8f1c5ca2530dc8"
          }
        },
        "5962948827d14db486b90d28d648abe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ButtonStyleModel",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "button_color": null,
            "font_weight": "",
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "173c2d7156914bdeb55e1cec36a6efb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "17%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3d6bc3b2f08f4df6aa5d955c79966e6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ButtonStyleModel",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "button_color": null,
            "font_weight": "",
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "168e0a22ff5c4e6082f9a49470353e9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "73683588e1a34288b4f80306cbc0057e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ButtonStyleModel",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "button_color": null,
            "font_weight": "",
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a90a474d7dd14bb78f2762d9c73ec278": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a120817eb4c24ac0b54d9decf134184d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e8f0d0ef466f4bc1bc8f1c5ca2530dc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sehJjtuBO3Hu"
      },
      "source": [
        "# https://colab.research.google.com/drive/1WbAd7ZuQNZXb2I1mZSjaXYUagcvpi889#scrollTo=2eDIEy2-wG9b&uniqifier=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEhxYplF0Nke"
      },
      "source": [
        "import copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4knu9pJy5Mu"
      },
      "source": [
        "def hash_list(c1, c2):\n",
        "  return \"cols: \" + str(c1) + \" | vals: \" + str(c2) \n",
        "\n",
        "def get_val_fact(map, cols, vals):\n",
        "  return map[hash_list(cols, vals)]\n",
        "\n",
        "class dataF:\n",
        "\n",
        "  def __init__(self,n_i,names,df_names,ed=[]):\n",
        "\n",
        "    self.n_i = n_i\n",
        "    self.names = names\n",
        "    self.n = len(self.names)\n",
        "    self.uniq = [set() for x in range(self.n)]\n",
        "    self.df_names = df_names\n",
        "    \n",
        "    # uniq values\n",
        "    for i in range(self.n_i):\n",
        "      row = df_names[i]\n",
        "      for j in range(self.n):\n",
        "        self.uniq[j].add(row[j])\n",
        "\n",
        "    self.hiper_param = 1\n",
        "    \n",
        "    #mapear elementos\n",
        "    self.mapElems()\n",
        "\n",
        "    # get ad and in list\n",
        "    self.lad = [[] for x in range(self.n)] \n",
        "    self.lin = [[] for x in range(self.n)]\n",
        "\n",
        "    for elem in ed:\n",
        "      u = self.mnames[elem[0]]\n",
        "      v = self.mnames[elem[1]]\n",
        "      self.lad[u].append(v)\n",
        "      self.lin[v].append(u)\n",
        "\n",
        "    self.initParents()\n",
        "    self.getFactors()\n",
        "\n",
        "    self.edges = []\n",
        "    for i in range(self.n):\n",
        "      u = self.names[i]\n",
        "      for x in self.lad[i]:\n",
        "        v = self.names[x]\n",
        "        self.edges.append([u, v])\n",
        "  \n",
        "  def mapElems(self):\n",
        "    # map columns\n",
        "    self.card = []\n",
        "    self.mnames = dict()\n",
        "    for x in range(self.n):\n",
        "      self.mnames[self.names[x]] = x\n",
        "    \n",
        "    self.mcvals = [dict() for x in range(self.n)]\n",
        "    for c in range(self.n):\n",
        "      self.uniq[c] = list(self.uniq[c])\n",
        "      self.card.append(len(self.uniq[c]))\n",
        "      for i in range(self.card[c]):\n",
        "        self.mcvals[c][self.uniq[c][i]] = i\n",
        "    \n",
        "    self.df = []\n",
        "    for row in self.df_names:\n",
        "      aux = []\n",
        "      for c in range(self.n):\n",
        "        aux.append(self.mcvals[c][row[c]])\n",
        "      \n",
        "      self.df.append(aux)\n",
        "\n",
        "  def initParents(self):  \n",
        "    self.parent = [-1]*self.n\n",
        "    flag = [0]*self.n\n",
        "\n",
        "    def dfs(u, p, vis):\n",
        "      if(vis[u]):\n",
        "        return \n",
        "      \n",
        "      vis[u] = True\n",
        "      self.parent[u] = p\n",
        "      for x in self.lad[u]:\n",
        "        dfs(x, u, vis) \n",
        "\n",
        "    self.root = -1\n",
        "    for x in range(self.n):\n",
        "      for y in self.lad[x]:\n",
        "        flag[y] = 1\n",
        "    \n",
        "    for x in range(self.n):\n",
        "      if(not flag[x]):\n",
        "        self.root = x\n",
        "        break\n",
        "\n",
        "    vis = [False]*self.n\n",
        "    dfs(self.root, -1, vis)\n",
        "\n",
        "  def getFactors(self):\n",
        "    self.mapFact = dict()\n",
        "    for i in range(self.n):\n",
        "      cols = [i] + self.lin[i] \n",
        "      fact = self.calcFactor(i)\n",
        "      for x in fact:\n",
        "        self.mapFact[hash_list(cols, x[:-1])] = x[-1]\n",
        "\n",
        "  def reset(self):\n",
        "    self.initParents()\n",
        "    self.getFactors()\n",
        "\n",
        "  def rep(self, params):\n",
        "    cnt = 0\n",
        "    for row in self.df:\n",
        "      ok = True\n",
        "      for x in params:\n",
        "        if(row[x[0]] != x[1]):\n",
        "            ok = False\n",
        "      if(ok):\n",
        "        cnt+= 1\n",
        "      \n",
        "    return cnt\n",
        "\n",
        "  def prob_general(self, params, factor):\n",
        "    # (m[value] + p) / (M + (p * card(column))\n",
        "    exp1 = self.rep(params) + self.hiper_param\n",
        "    exp2 = self.n_i + (self.hiper_param * factor)\n",
        "    return round(exp1/exp2,6) \n",
        "      \n",
        "  def calcFactor(self, id):\n",
        "\n",
        "    def normalize(arr):\n",
        "      s = 0\n",
        "      ans = []\n",
        "\n",
        "      for x in arr:\n",
        "        s+= x\n",
        "      \n",
        "      for x in arr:\n",
        "        ans.append(x/s)\n",
        "      \n",
        "      return ans\n",
        "      \n",
        "    def add_column(M, col):\n",
        "      for i in range(len(col)):\n",
        "        M[i].append(col[i])\n",
        "\n",
        "    cols = [id] + self.lin[id]\n",
        "\n",
        "    uniqs = []\n",
        "    cnt = []\n",
        "    ids = []\n",
        "    vuelta = []\n",
        "    total = 1\n",
        "\n",
        "    for x in cols:\n",
        "\n",
        "        uniqs.append([i for i in range(self.card[x])])\n",
        "        ids.append(total)\n",
        "            \n",
        "        total*= self.card[x]\n",
        "        \n",
        "        cnt.append(0)\n",
        "        vuelta.append(0)\n",
        "\n",
        "    D = []\n",
        "    c_ans = []\n",
        "    c_norm = []\n",
        "    M = []\n",
        "\n",
        "    for u in range(total):\n",
        "        vals = []\n",
        "        i = 0\n",
        "        for x in cols:\n",
        "            vals.append([x, uniqs[i][cnt[i]]])\n",
        "            i+= 1\n",
        "        \n",
        "        M.append( [e[1] for e in vals] )\n",
        "\n",
        "        exp1 = self.prob_general(vals, total)\n",
        "        exp2 = self.prob_general(vals[1:], total/self.card[id])\n",
        "\n",
        "        if(len(self.lin[id]) == 0):\n",
        "          D.append(exp1)\n",
        "        \n",
        "        else:\n",
        "          D.append(exp1/exp2)\n",
        "\n",
        "        for j in range(len(cols)):\n",
        "            vuelta[j]+= 1\n",
        "            if(vuelta[j] == ids[j]):\n",
        "                cnt[j] = (cnt[j] + 1)%len(uniqs[j])\n",
        "                vuelta[j] = 0\n",
        "\n",
        "        if(len(D) == self.card[id]):\n",
        "          c_ans+= D\n",
        "          c_norm+= normalize(D)\n",
        "          D = []\n",
        "          \n",
        "    # Agregando columnas\n",
        "    add_column(M, c_norm)\n",
        "\n",
        "    return M\n",
        "\n",
        "\n",
        "def Entropia(D):\n",
        "  ans = 0\n",
        "  for i in range(D.n):\n",
        "    combs = D.calcFactor(i)\n",
        "    for x in range(len(combs)):\n",
        "      combs[x] = combs[x][:-1]\n",
        "\n",
        "    for comb in combs:\n",
        "      params = [[i, comb[0]]]\n",
        "      for id in range(1, len(comb)):\n",
        "        params.append([ D.lin[i][id - 1] , comb[id]])\n",
        "      \n",
        "\n",
        "      Nijk = D.rep(params)\n",
        "      a = Nijk/D.n_i\n",
        "      \n",
        "      params = params[1:]\n",
        "      den = D.n_i\n",
        "      \n",
        "      if(params):\n",
        "        den = D.rep(params)\n",
        "\n",
        "      if(Nijk == 0):\n",
        "        continue\n",
        "\n",
        "      b = math.log2(Nijk/den)\n",
        "\n",
        "      ans+= a*b\n",
        "  \n",
        "  return -D.n_i*ans\n",
        "\n",
        "def AIC(D):\n",
        "  K = 0\n",
        "  for i in range(D.n):\n",
        "    q = 1\n",
        "    for x in D.lin[i]:\n",
        "      q *= D.card[x]\n",
        "\n",
        "    K+= (D.card[i]-1)*q\n",
        "  \n",
        "  return Entropia(db) + K\n",
        "\n",
        "def MDL(D):\n",
        "  K = 0\n",
        "  for i in range(D.n):\n",
        "    q = 1\n",
        "    for x in D.lin[i]:\n",
        "      q *= D.card[x]\n",
        "\n",
        "    K+= (D.card[i]-1)*q\n",
        "  \n",
        "  return Entropia(db) + K*math.log2(D.n_i)/2.0\n",
        "\n",
        "def hk2(D):\n",
        "\n",
        "  def fact(num):\n",
        "    ans = 1\n",
        "    while(num > 0):\n",
        "      ans*= num\n",
        "      num-= 1\n",
        "    \n",
        "    return ans\n",
        "\n",
        "  ans = 1\n",
        "  for i in range(D.n):\n",
        "    P = D.parent[i]\n",
        "    if(P != -1):\n",
        "      for j in range(D.card[P]):\n",
        "        Nij = D.rep([ [ P , j ] ] )\n",
        "        term = 1\n",
        "        for k in range(D.card[i]):\n",
        "          Nijk = D.rep([ [P, j] , [i , k ] ])\n",
        "          term*= fact(Nijk)\n",
        "\n",
        "        \n",
        "        term*= fact(D.card[i] - 1)/fact(D.card[i] - 1 + Nij)\n",
        "        \n",
        "        ans*= term\n",
        "\n",
        "  return ans\n",
        "\n",
        "def K2(D, lb, ub, metrica, order=None):\n",
        "\n",
        "  def getEdges(nodes_parents, i=None, parents_i={}):\n",
        "    ed = []\n",
        "\n",
        "    for x in nodes_parents:\n",
        "      for p in nodes_parents[x]:\n",
        "        ed.append([p,x])\n",
        "    \n",
        "    if(i != None):\n",
        "      for p in parents_i:\n",
        "        ed.append([p, i])\n",
        "\n",
        "    return ed\n",
        "\n",
        "\n",
        "  nodes = D.names if order is None else order\n",
        "  \n",
        "  nodes_parents = {x: [] for x in nodes}\n",
        "  scores = {'AIC': AIC, 'Entropy': Entropia, 'MDL': MDL, 'K2': hk2}\n",
        "\n",
        "\n",
        "  for i in range(len(nodes)):\n",
        "      parents_i = []\n",
        "      \n",
        "      P_old = scores[metrica](dataF(D.n_i, D.names, D.df_names, getEdges(nodes_parents, nodes[i], parents_i)))\n",
        "      OKToProceed = True\n",
        "\n",
        "      while OKToProceed and len(parents_i) < ub and i > 0:\n",
        "        pred = [ nodes[ii] for ii in range(i)]\n",
        "\n",
        "        maxs = []\n",
        "\n",
        "        for node in pred:\n",
        "          maxs.append(scores[metrica](dataF(D.n_i, D.names, D.df_names, getEdges(nodes_parents, nodes[i], parents_i + [node]))))\n",
        "    \n",
        "        mx = max(maxs)\n",
        "        z = pred[maxs.index(mx)]\n",
        "        P_new = mx\n",
        "\n",
        "        if P_new > P_old:\n",
        "          P_old = P_new\n",
        "          parents_i.append(z)\n",
        "\n",
        "        else:\n",
        "          if(len(parents_i) < lb):\n",
        "            parents_i.append(z)\n",
        "\n",
        "          OKToProceed = False\n",
        "\n",
        "      nodes_parents[nodes[i]] = parents_i\n",
        "      # print(\"Nodo: \", nodes[i], \" padres de Nodo => \", parents_i)\n",
        "\n",
        "  return dataF(D.n_i, D.names, D.df_names, getEdges(nodes_parents))\n",
        "\n",
        "def greedyLS(D, metrica):\n",
        "\n",
        "  def cycle(u, G, vis, reStack):\n",
        "    if(not vis[u]):\n",
        "      vis[u] = True\n",
        "      reStack[u] = True\n",
        "\n",
        "      for x in G.lad[u]:\n",
        "        if(not vis[x] and cycle(x, G, vis, reStack)):\n",
        "          return True\n",
        "        elif(reStack[x]):\n",
        "          return True\n",
        "      \n",
        "    reStack[u] = False\n",
        "    return False\n",
        "\n",
        "  def isValid(G):\n",
        "    vis = [False]*G.n\n",
        "    reStack = [False]*G.n \n",
        "\n",
        "    for i in range(G.n):\n",
        "      if(cycle(i, G, vis, reStack)):\n",
        "        return False\n",
        "    \n",
        "    return True\n",
        "    \n",
        "  # Extrayendo lista de nodos\n",
        "  nodes = D.names\n",
        "    \n",
        "  # Scores\n",
        "  scores = {'AIC': AIC, 'Entropy': Entropia, 'MDL': MDL, 'K2': hk2}\n",
        " \n",
        "  # 1. σbest ← σi\n",
        "  omega_best = copy.deepcopy(D)\n",
        "  score_best = scores[metrica](omega_best)\n",
        "\n",
        "  # 2. do\n",
        "  while True:\n",
        "      \n",
        "    # 3. σ ← σbest\n",
        "    O = copy.deepcopy(omega_best)\n",
        "\n",
        "    # 4.\n",
        "    progress = False\n",
        "\n",
        "    # 5. for each operator o ∈ O\n",
        "    for node in nodes:\n",
        "          \n",
        "      cases = []\n",
        "      \n",
        "      for edge in O.edges:\n",
        "        aux = [e for e in O.edges if e != edge]\n",
        "        cases.append(dataF(O.n_i, O.names, O.df_names, aux))\n",
        "        cases.append(dataF(O.n_i, O.names, O.df_names, aux + [[edge[1], edge[0]]]))\n",
        "          \n",
        "      for node2 in nodes:\n",
        "        if([node, node2] not in O.edges and node != node2):\n",
        "          cases.append(dataF(O.n_i, O.names, O.df_names, O.edges + [[node, node2]] ))         \n",
        "\n",
        "      for case in cases:\n",
        "        if isValid(case):\n",
        "          score_o = scores[metrica](case)\n",
        "          if score_o > score_best:\n",
        "            omega_best = copy.deepcopy(case)\n",
        "            score_best = score_o\n",
        "            progress = True\n",
        " \n",
        "    if not progress:\n",
        "      break\n",
        "    \n",
        "  return omega_best"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHjmBBf6Sfg6"
      },
      "source": [
        "**Bag of Words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSQWxBDOSigZ"
      },
      "source": [
        "import math\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import spacy\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BrfJIaMSjbF",
        "outputId": "4e92049d-3ec3-4735-b66f-eacd99515a23"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qe4S7HIDSq-x",
        "outputId": "1c8ad438-b90c-4bd1-b9bc-23668aae3f6e"
      },
      "source": [
        "spacy.cli.download('es_core_news_md')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('es_core_news_md')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMIZTKv4Ss-i"
      },
      "source": [
        "nlp = spacy.load('es_core_news_md')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvYpKSKESu5N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41ca6c2a-70ab-4458-e7df-ea2f07f9534a"
      },
      "source": [
        "stopwords = nlp.Defaults.stop_words\n",
        "print(stopwords)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'grandes', 'pesar', 'hoy', 'tras', 'estais', 'indicó', 'raras', 'anterior', 'cierto', 'cuenta', 'demás', 'aquellas', 'usa', 'había', 'tuya', 'breve', 'cierta', 'explicó', 'cuantos', 'consiguen', 'asi', 'dan', 'misma', 'eras', 'ciertas', 'vaya', 'acuerdo', 'través', 'temprano', 'les', 'poco', 'ya', 'veces', 'junto', 'como', 'hecho', 'hubo', 'esta', 'señaló', 'todavía', 'dentro', 'trata', 'partir', 'valor', 'haya', 'afirmó', 'puedo', 'segunda', 'usas', 'he', 'nosotras', 'sido', 'vuestro', 'podria', 'antano', 'quiza', 'días', 'debajo', 'empleo', 'pero', 'hacer', 'ese', 'conmigo', 'casi', 'pronto', 'serán', 'hizo', 'habían', 'otros', 'tampoco', 'pasado', 'última', 'aqui', 'su', 'intentas', 'tiempo', 'usar', 'tú', 'dice', 'cualquier', 'gran', 'siempre', 'quien', 'quiere', 'vuestros', 'uno', 'poder', 'creo', 'si', 'mios', 'cuánto', 'vosotras', 'dijeron', 'le', 'apenas', 'vez', 'tanto', 'os', 'aquél', 'próximos', 'hacia', 'pocos', 'quién', 'último', 'primera', 'podeis', 'ciertos', 'últimos', 'cómo', 'se', 'aquéllas', 'alguno', 'hacerlo', 'otro', 'cosas', 'verdad', 'queremos', 'largo', 'detras', 'sobre', 'considera', 'solo', 'también', 'horas', 'podrán', 'hemos', 'alrededor', 'cual', 'tuyo', 'tuyos', 'mis', 'aquel', 'ampleamos', 'principalmente', 'ultimo', 'cuantas', 'dicho', 'era', 'podrias', 'tuvo', 'además', 'tercera', 'dónde', 'ex', 'saben', 'usais', 'habla', 'van', 'nuevas', 'mia', 'tenga', 'otras', 'algunos', 'pais', 'sois', 'ademas', 'tres', 'expresó', 'ésos', 'debe', 'añadió', 'intentan', 'entonces', 'final', 'dar', 'realizar', 'tienen', 'aquí', 'llegó', 'total', 'han', 'porque', 'adelante', 'todas', 'bastante', 'esto', 'comentó', 'aquello', 'igual', 'estados', 'ninguno', 'ésas', 'alguna', 'tan', 'salvo', 'menudo', 'buenos', 'nadie', 'unos', 'hacemos', 'nueva', 'cuál', 'ver', 'trabajamos', 'que', 'podría', 'proximo', 'para', 'ejemplo', 'primeros', 'aseguró', 'posible', 'lejos', 'qué', 'suyas', 'ahora', 'un', 'donde', 'deben', 'ante', 'siete', 'ambos', 'las', 'esa', 'habia', 'pasada', 'ése', 'contra', 'míos', 'emplear', 'aquélla', 'nunca', 'estuvo', 'somos', 'dado', 'eran', 'todavia', 'arribaabajo', 'tambien', 'ningún', 'varias', 'mas', 'mejor', 'mismo', 'fue', 'aquéllos', 'arriba', 'quizas', 'dicen', 'ningunas', 'repente', 'despues', 'del', 'sí', 'bueno', 'cuáles', 'siguiente', 'aquella', 'ellos', 'quienes', 'quiénes', 'propio', 'usamos', 'esos', 'existe', 'excepto', 'llevar', 'éste', 'encima', 'algún', 'más', 'trabajais', 'haces', 'ayer', 'dejó', 'atras', 'consigo', 'nosotros', 'poner', 'dio', 'estará', 'qeu', 'de', 'cuales', 'diferentes', 'nuestro', 'buena', 'mediante', 'cuántas', 'consigues', 'lo', 'no', 'informó', 'alli', 'allí', 'hicieron', 'esas', 'eramos', 'hace', 'tiene', 'adrede', 'lleva', 'intento', 'verdadero', 'habrá', 'los', 'fueron', 'ahí', 'seis', 'mi', 'otra', 'ésa', 'estas', 'éstas', 'estado', 'yo', 'buenas', 'ninguna', 'vosotros', 'últimas', 'haber', 'trabajar', 'detrás', 'enseguida', 'claro', 'eso', 'nuestros', 'aunque', 'mismos', 'podemos', 'nuestras', 'ello', 'quedó', 'sin', 'nuevo', 'estos', 'ustedes', 'saber', 'una', 'intentar', 'tuyas', 'modo', 'la', 'usted', 'nuevos', 'intenta', 'despacio', 'medio', 'respecto', 'mio', 'mayor', 'parece', 'poca', 'sería', 'eres', 'cuanta', 'estan', 'estamos', 'empleais', 'quizá', 'ésta', 'hasta', 'mí', 'realizado', 'usan', 'verdadera', 'están', 'quizás', 'trabajo', 'vuestra', 'estaban', 'mía', 'próximo', 'tenido', 'sean', 'mucha', 'sea', 'podrian', 'solamente', 'tendrán', 'aun', 'durante', 'tenemos', 'tendrá', 'solos', 'conocer', 'debido', 'bien', 'cada', 'dias', 'voy', 'consigue', 'todo', 'ocho', 'toda', 'sabemos', 'propias', 'está', 'primer', 'hablan', 'todos', 'dos', 'él', 'incluso', 'ella', 'fin', 'según', 'embargo', 'ni', 'estar', 'cuando', 'deprisa', 'podrá', 'vais', 'hago', 'luego', 'tengo', 'estaba', 'mías', 'empleas', 'diferente', 'cuanto', 'antes', 'mias', 'tu', 'me', 'vuestras', 'dijo', 'pudo', 'fui', 'general', 'desde', 'dia', 'tener', 'tal', 'ningunos', 'ti', 'este', 'emplean', 'cuándo', 'realizó', 'consideró', 'propia', 'intentais', 'trabaja', 'solas', 'sé', 'tenía', 'cerca', 'nos', 'pocas', 'algo', 'momento', 'sino', 'teneis', 'delante', 'después', 'manera', 'va', 'ahi', 'aquellos', 'dieron', 'trabajas', 'así', 'haceis', 'soyos', 'cinco', 'sabes', 'son', 'éstos', 'pueden', 'actualmente', 'ir', 'podrían', 'mío', 'con', 'parte', 'supuesto', 'paìs', 'al', 'informo', 'mencionó', 'conseguimos', 'hay', 'siendo', 'existen', 'agregó', 'tarde', 'segun', 'tus', 'haciendo', 'cuántos', 'da', 'intentamos', 'propios', 'trabajan', 'sabe', 'entre', 'cuánta', 'es', 'te', 'nuestra', 'mismas', 'muy', 'fuera', 'antaño', 'conseguir', 'podriamos', 'sigue', 'mal', 'sabeis', 'puede', 'menos', 'primero', 'contigo', 'lugar', 'decir', 'estoy', 'aún', 'enfrente', 'ha', 'soy', 'fuimos', 'por', 'uso', 'segundo', 'sola', 'sus', 'el', 'peor', 'pueda', 'vamos', 'muchos', 'en', 'podriais', 'manifestó', 'bajo', 'hacen', 'suyo', 'mientras', 'varios', 'cuatro', 'nada', 'sera', 'será', 'mucho', 'pues', 'día', 'ellas', 'suya', 'encuentra', 'demasiado', 'gueno', 'lado', 'ser', 'algunas', 'unas', 'aproximadamente', 'muchas', 'buen', 'sólo'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIeC8nWrS4bL"
      },
      "source": [
        "def add_stop_word(stopword):\n",
        "  nlp.vocab[stopword].is_stop = True\n",
        "  stopwords.add(stopword)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJ5yH4bMkAVC"
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from unicodedata import normalize\n",
        "\n",
        "\n",
        "def process_text(text):\n",
        "  \n",
        "  def filter_non_an(X):\n",
        "    PERMITTED_CHARS = \"0123456789abcdefghijklmnñopqrstuvwxyzABCDEFGHIJKLMNÑOPQRSTUVWXYZ \"   \n",
        "    ans = \"\"\n",
        "    for x in X:\n",
        "      if(x in PERMITTED_CHARS):\n",
        "          ans+=x\n",
        "      else:\n",
        "        ans+=\" \"\n",
        "\n",
        "    return ans\n",
        "\n",
        "  if(not isinstance(text, str)):\n",
        "    return \"\"\n",
        "\n",
        "  aux =  ' '.join(x for x in text.split() if not x.startswith('@'))\n",
        "  aux = aux.lower()\n",
        "\n",
        "  # -> NFD y eliminar diacríticos\n",
        "  aux = re.sub(\n",
        "          r\"([^n\\u0300-\\u036f]|n(?!\\u0303(?![\\u0300-\\u036f])))[\\u0300-\\u036f]+\", r\"\\1\", \n",
        "          normalize( \"NFD\", aux), 0, re.I\n",
        "      )\n",
        "\n",
        "  # -> NFC\n",
        "  aux = normalize( 'NFC', aux)\n",
        "\n",
        "  aux = filter_non_an(aux)\n",
        "  aux = re.sub(' +', ' ', aux)\n",
        "  \n",
        "  return aux\n",
        "\n",
        "def readFile(file, lim = 50):\n",
        "  df = pd.read_excel (file)\n",
        "\n",
        "  names = df.columns\n",
        "  df_names = []\n",
        "\n",
        "  pos = []\n",
        "  neu = []\n",
        "  neg = []\n",
        "\n",
        "  for text in df.values.tolist():\n",
        "    \n",
        "    aux = process_text(text[0])\n",
        "\n",
        "    if(len(aux) > 0 and not aux.isspace()):\n",
        "      if(text[1] == 'Positivo'):\n",
        "        pos.append([aux, text[1]])\n",
        "      elif(text[1] == 'Neutro'):\n",
        "        neu.append([aux, text[1]])\n",
        "      else:\n",
        "        neg.append([aux, text[1]])\n",
        "  \n",
        "\n",
        "  part = int(min(lim/3, len(pos), len(neu), len(neg)))\n",
        "  df_names = pos[:part] + neu[:part] + neg[:part] \n",
        "\n",
        "  return len(df_names), names, df_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5jCFTcwupfW"
      },
      "source": [
        "import random\n",
        "\n",
        "def get_filtered_df(df, n_i, max_nodes = 500):\n",
        "\n",
        "  ls = []\n",
        "  \n",
        "  for X,Y in df:\n",
        "    ls+= X.split(' ')\n",
        "  \n",
        "  unique_words = list(set(ls))\n",
        "  random.shuffle(unique_words)\n",
        "\n",
        "\n",
        "  print(unique_words)\n",
        "\n",
        "  dif = len(unique_words) - max_nodes\n",
        "  print(dif)\n",
        "  \n",
        "  if(dif > 0):\n",
        "    for i in range(dif):\n",
        "      add_stop_word(unique_words[i])\n",
        "  \n",
        "  df_new = []\n",
        "  for i in range(len(df)):\n",
        "    X, Y = df[i]\n",
        "    X = ' '.join(x for x in X.split(' ') if nlp.vocab[x].is_stop == False)\n",
        "    X = re.sub(' +', ' ', X)\n",
        "    \n",
        "    if(len(X) != 0):\n",
        "      df_new.append([X, Y])\n",
        "\n",
        "  return n_i, df_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Xe5E9vtpcaB"
      },
      "source": [
        "# n_i, df_names = get_filtered_df(df_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSF5W4dFxYmC"
      },
      "source": [
        "def bag_of_words(data):\n",
        "  bag_of_words = []\n",
        "  for text, spam in data:\n",
        "    words = text.split(\" \")\n",
        "    new_text = \"\"\n",
        "    for word in words:\n",
        "      if nlp.vocab[word].is_stop:\n",
        "        pass\n",
        "      else:\n",
        "        new_text += word + \" \"\n",
        "    bag_of_words.append([new_text, spam])\n",
        "  \n",
        "  bag_of_words_tokens = []\n",
        "  for text, spam in data:\n",
        "    tokens = word_tokenize(text, 'spanish')\n",
        "    tokens = [w.lower() for w in tokens if w.isalpha() and nlp.vocab[w].is_stop == False]\n",
        "    bag_of_words_tokens.append([tokens, spam])\n",
        "\n",
        "  tokens = {}\n",
        "  for text, spam in data:\n",
        "    words = word_tokenize(text, 'spanish')\n",
        "    words = [w.lower() for w in words if w.isalpha() and nlp.vocab[w].is_stop == False]\n",
        "    for w in words:\n",
        "      if w.isalpha() and nlp.vocab[w].is_stop == False:\n",
        "        if w not in tokens:\n",
        "          tokens[w] = 0\n",
        "        if w in tokens:\n",
        "          tokens[w] += 1\n",
        "  \n",
        "  keys = list(tokens.keys())\n",
        "\n",
        "  bag_of_words = []\n",
        "  quantity = []\n",
        "  for text, spam in data:\n",
        "    words = word_tokenize(text, 'spanish')\n",
        "    words = [w.lower() for w in words if w.isalpha() and nlp.vocab[w].is_stop == False]\n",
        "    bag = [0] * len(tokens)\n",
        "    q = [0] * len(tokens)\n",
        "    for i in range(len(words)):\n",
        "      word = words[i]\n",
        "      if word in keys:\n",
        "        index = keys.index(word)\n",
        "        bag[index] = 1\n",
        "        q[index] += 1\n",
        "    bag_of_words.append(bag)\n",
        "    quantity.append(q)\n",
        "\n",
        "  header_generated = []\n",
        "  for key in keys:\n",
        "    header_generated.append(key)\n",
        "  header_generated.append('Etiquetado')\n",
        "  data_generated = []\n",
        "  for i in range(len(bag_of_words)):\n",
        "    e = []\n",
        "    for b in bag_of_words[i]:\n",
        "      e.append(b == 1)\n",
        "    e.append(bag_of_words_tokens[i][1])\n",
        "    data_generated.append(e)\n",
        "  \n",
        "  n_i = len(data_generated)\n",
        "  names = header_generated\n",
        "  df_names = data_generated\n",
        "\n",
        "  db = dataF(n_i, names, df_names)\n",
        "\n",
        "  return db"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMgjuihzV4pz"
      },
      "source": [
        "def get_transponse(edges):\n",
        "  n = len(edges)\n",
        "  aux = [[] for _ in range(n)]\n",
        "  for i in range(n):\n",
        "    for x in edges[i]:\n",
        "      aux[x].append(i)\n",
        "  \n",
        "  return aux\n",
        "\n",
        "def get_topo_sort(edges):\n",
        "  \n",
        "  trans = get_transponse(edges)\n",
        "\n",
        "  def dfs(x, visited, ts):\n",
        "    if(visited[x]):\n",
        "      return\n",
        "    \n",
        "    visited[x] = True\n",
        "    for y in trans[x]:\n",
        "      dfs(y, visited, ts)\n",
        "    \n",
        "    ts.append(x)\n",
        "\n",
        "  n = len(trans)\n",
        "  visited = [False for i in range(n)]\n",
        "  ts = []\n",
        "\n",
        "  for i in range(n):\n",
        "    if(not visited[i]):\n",
        "      dfs(i, visited, ts)\n",
        "  \n",
        "  return ts[::-1]\n",
        "\n",
        "def get_matrix_factor(cols, df):\n",
        "  uniqs = []\n",
        "  cnt = []\n",
        "  ids = []\n",
        "  vuelta = []\n",
        "  total = 1\n",
        "\n",
        "  for x in cols:\n",
        "\n",
        "      uniqs.append([i for i in range(df.card[x])])\n",
        "      ids.append(total)\n",
        "          \n",
        "      total*= df.card[x]\n",
        "      \n",
        "      cnt.append(0)\n",
        "      vuelta.append(0)\n",
        "      \n",
        "  M = []\n",
        "\n",
        "  for u in range(total):\n",
        "      vals = []\n",
        "      i = 0\n",
        "      for x in cols:\n",
        "          vals.append([x, uniqs[i][cnt[i]]])\n",
        "          i+= 1\n",
        "      \n",
        "      M.append( [e[1] for e in vals] + [1])\n",
        "\n",
        "      for j in range(len(cols)):\n",
        "          vuelta[j]+= 1\n",
        "          if(vuelta[j] == ids[j]):\n",
        "              cnt[j] = (cnt[j] + 1)%len(uniqs[j])\n",
        "              vuelta[j] = 0\n",
        "  \n",
        "  return M\n",
        "\n",
        "def columns_order(c1, c2):\n",
        "  c3 = []\n",
        "  for i in range(1, len(c1)):\n",
        "    c3.append((c1[i], c2[i]))\n",
        "\n",
        "  c3.sort(key = lambda x: x[0])\n",
        "  \n",
        "  for i in range(1, len(c1)):\n",
        "    c1[i], c2[i] = c3[i-1]\n",
        "\n",
        "def get_sum_matrix(map_cols,mult_fact,row,new_cols,k):\n",
        "  sum = 0\n",
        "  for ROW in mult_fact:\n",
        "    NR = ROW[:-1]\n",
        "    NR.pop(map_cols[k])\n",
        "    if(NR == row):\n",
        "      sum+= ROW[-1]\n",
        "\n",
        "  return sum\n",
        "\n",
        "def hash_list_2(c1, c2):\n",
        "  return \"cols: \" + str(c1) + \" | vals: \" + str(c2) \n",
        "\n",
        "def get_val_fact_2(map, cols, vals):\n",
        "  return map[hash_list_2(cols, vals)] \n",
        "\n",
        "def query(map, df, ev, ev_val, q, orden=[]):\n",
        "\n",
        "  def get_unique_cols(mx):\n",
        "    st = set()\n",
        "    for x in mx:\n",
        "      for elem in x:\n",
        "        st.add(elem)\n",
        "\n",
        "    st = list(st)\n",
        "    st.sort()\n",
        "\n",
        "    return st\n",
        "  \n",
        "  if(len(orden) == 0):\n",
        "    orden = get_topo_sort(df.lin)\n",
        "  \n",
        "  n = len(orden)\n",
        "  orden = [x for x in orden if x not in ev and x not in q]\n",
        "\n",
        "  factor_names = []\n",
        "  added_factor = []\n",
        "\n",
        "  map_factores = dict()\n",
        "  for i in range(n):\n",
        "    factor_names.append([i] + df.lin[i])\n",
        "  for k in orden: #topo sort con ocultas\n",
        "    \n",
        "    rem = [x for x in factor_names if k in x]\n",
        "    arem = [x for x in added_factor if k in x]\n",
        "\n",
        "    cols = get_unique_cols(rem + arem)\n",
        "    map_cols = dict()\n",
        "\n",
        "    for i in range(len(cols)):\n",
        "      map_cols[cols[i]] = i\n",
        "\n",
        "\n",
        "    mult_fact = get_matrix_factor(cols, df)\n",
        " \n",
        "    # multiplicacion\n",
        "    for row in mult_fact:\n",
        "      for fact in rem:\n",
        "        vals_ = []\n",
        "        for f in fact:\n",
        "          vals_.append(row[map_cols[f]])\n",
        "    \n",
        "        row[-1]*= get_val_fact(map,fact,vals_)\n",
        "      \n",
        "      for fact in arem:\n",
        "        vals_ = []\n",
        "        for f in fact:\n",
        "          vals_.append(row[map_cols[f]])\n",
        "    \n",
        "        row[-1]*= get_val_fact_2(map_factores,fact,vals_)\n",
        "    \n",
        "    \n",
        "    #suma\n",
        "    new_cols = cols.copy()\n",
        "    new_cols.remove(k)\n",
        "    new_mult_fact = get_matrix_factor(new_cols, df)\n",
        "\n",
        "    for row in new_mult_fact:\n",
        "      row[-1] = get_sum_matrix(map_cols,mult_fact,row[:-1],new_cols,k)\n",
        "\n",
        "\n",
        "    #agregar nuevo factor\n",
        "    if(new_cols):\n",
        "      added_factor.append(new_cols)\n",
        "      for x in new_mult_fact:\n",
        "        aux = hash_list_2(new_cols, x[:-1])\n",
        "        if(aux in map_factores):\n",
        "          map_factores[aux]*= x[-1]\n",
        "        else:\n",
        "          map_factores[aux] = x[-1]\n",
        "\n",
        "    for x in rem:\n",
        "      factor_names.remove(x)\n",
        "    \n",
        "    for x in arem:\n",
        "      added_factor.remove(x)\n",
        "\n",
        "\n",
        "\n",
        "  # multiplicaion final y argmax para la query\n",
        "  cols = get_unique_cols(factor_names + added_factor)\n",
        "  map_cols = dict()\n",
        "\n",
        "  for i in range(len(cols)):\n",
        "    map_cols[cols[i]] = i\n",
        "\n",
        "  k = q[0]\n",
        "  id_col = map_cols[k]\n",
        "  card = df.card[k]\n",
        "\n",
        "  FF = get_matrix_factor(cols, df)\n",
        "\n",
        "  for row in FF:\n",
        "    for fact in factor_names:\n",
        "      vals_ = []\n",
        "      for f in fact:\n",
        "        vals_.append(row[map_cols[f]])\n",
        "      \n",
        "      row[-1]*= get_val_fact(map,fact,vals_)\n",
        "    \n",
        "    for fact in added_factor:\n",
        "      vals_ = []\n",
        "      for f in fact:\n",
        "        vals_.append(row[map_cols[f]])\n",
        "    \n",
        "      row[-1]*= get_val_fact_2(map_factores,fact,vals_)\n",
        "\n",
        "  # argmax\n",
        "\n",
        "\n",
        "  arg = dict()\n",
        "\n",
        "  for i in range(card):\n",
        "    arg[i] = 0\n",
        "\n",
        "  # print(cols)\n",
        "\n",
        "  for row in FF:\n",
        "    ok = 1\n",
        "    for i in range(len(ev)):\n",
        "      c_ = map_cols[ev[i]]\n",
        "      if(row[c_] != ev_val[i]):\n",
        "        ok = 0\n",
        "    \n",
        "    if(ok):\n",
        "      # print(row)\n",
        "      arg[row[id_col]]+= row[-1]\n",
        "  \n",
        "  print(\"-----------------\")\n",
        "\n",
        "  maxargs = [None, 0]\n",
        "  for x in arg:\n",
        "    if(arg[x] > maxargs[1]):\n",
        "      maxargs = [x,arg[x]]\n",
        "\n",
        "  print(\"maxargs: \", maxargs)\n",
        "\n",
        "  return arg, maxargs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obbx8zcPXm6E"
      },
      "source": [
        "def predict_query(d, test):\n",
        "  print(test)\n",
        "\n",
        "  test = process_text(test)\n",
        "\n",
        "  ev = []\n",
        "  ev_val = []\n",
        "  \n",
        "  test = test.split(' ') \n",
        "\n",
        "  print(test)\n",
        "\n",
        "  for i in range(len(test)):\n",
        "    if(test[i] in d.names):\n",
        "      ev.append(d.mnames[test[i]])\n",
        "      ev_val.append(1)\n",
        "  \n",
        "  if(len(ev) == 0):\n",
        "    return {0 : 0.3, 1 : 0.3, 2 : 0.3} , [d.mcvals[len(d.names) - 1]['Neutro'], 0.3] \n",
        "\n",
        "  return query(d.mapFact, d, ev, ev_val, [ d.mnames[\"Etiquetado\"] ])  \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBp3_B_-nIh3"
      },
      "source": [
        "# df_names_len = len(df_names)\n",
        "# cut = int(df_names_len * 0.7)\n",
        "# train = df_names[0:cut]\n",
        "# test = df_names[cut:df_names_len]\n",
        "# db = bag_of_words(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzugiOEmz7_t"
      },
      "source": [
        "Aprendizaje Supervisado y PLN:] se debe entrenar redes bayesianas generadas usando (1) hill-climbing/greedy, (2) b´usqueda K2 con la m´etrica entrop´ıa y m´etrica\n",
        "K2 con vectorizaci´on bag-of-words. Aplicar las m´etricas de desempe˜no vistas en clase:\n",
        "F1, precisi´on, recall, accuracy, gr´aficos ROC y plasmar conclusiones al respecto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56yIHx7l0cMn"
      },
      "source": [
        "# db_k2 = K2(db, 4, 5, 'K2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wG0PfJXaLKdg"
      },
      "source": [
        "# predict_query(db_k2, 'fiore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgLx2otMZSLW"
      },
      "source": [
        "# x = predict_query(db_k2, 'gracias gustar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPra-GBbIwFl"
      },
      "source": [
        "def getPredicts(db, test):\n",
        "  data_test_Y = []\n",
        "  data_real = []\n",
        "\n",
        "  for elem in test:\n",
        "    x = predict_query(db, elem[0])\n",
        "    data_test_Y.append(x[1])\n",
        "    data_real.append(elem[1])\n",
        "\n",
        "  return data_real, data_test_Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6h5jpq_Jrvj"
      },
      "source": [
        "def divide(n, d):\n",
        "    return n / d if d else 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTNY2KjlJoDS"
      },
      "source": [
        "class metrics:\n",
        "  def __init__(self, data_test,data_pred,name=\"auc.png\"):\n",
        "\n",
        "    for i in range(len(data_test)):\n",
        "      if data_test[i] == 'Negativo':\n",
        "        data_test[i] = 2\n",
        "      elif data_test[i] == 'Positivo':\n",
        "        data_test[i] = 0\n",
        "      elif data_test[i] == 'Neutral':\n",
        "        data_test[i] = 1\n",
        "\n",
        "    self.scores = data_pred\n",
        "    self.real = data_test\n",
        "\n",
        "    self.N = data_test.count(2)\n",
        "    self.Ntl = data_test.count(1)\n",
        "    self.P = data_test.count(0)\n",
        "\n",
        "    self.TP = 0\n",
        "    self.FP = 0\n",
        "\n",
        "    self.TN = 0\n",
        "    self.FN = 0\n",
        "\n",
        "    self.TNtl = 0\n",
        "    self.FNtl = 0\n",
        "\n",
        "    self.name = name\n",
        "\n",
        "    for i in range(len(data_test)):\n",
        "      if data_test[i] == 0 and data_pred[i][0] == 0:\n",
        "        self.TP += 1\n",
        "      elif data_test[i] != 0 and data_pred[i][0] == 0:\n",
        "        self.FP += 1\n",
        "      elif data_test[i] != 2 and data_pred[i][0] == 2:\n",
        "        self.FN += 1\n",
        "      elif data_test[i] == 2 and data_pred[i][0] == 2:\n",
        "        self.TN += 1\n",
        "      elif data_test[i] != 1 and data_pred[i][0] == 1:\n",
        "        self.FNtl += 1\n",
        "      elif data_test[i] == 1 and data_pred[i][0] == 1:\n",
        "        self.TNtl += 1\n",
        "\n",
        "  def __str__(self):\n",
        "    string = \"\"\"\n",
        "    P: {}\n",
        "    N: {}\n",
        "    TP: {}\n",
        "    FP: {}\n",
        "    TN: {}\n",
        "    FN: {}\n",
        "    \"\"\".format(self.P,self.N,self.TP,self.FP,self.TN,self.TN)\n",
        "    return string\n",
        "\n",
        "  def precision_score(self,clase):\n",
        "    if clase == 0:\n",
        "      return divide(self.TP,(self.FP+self.TP))\n",
        "    elif clase == 2:\n",
        "      return divide(self.TN,(self.FN+self.TN))\n",
        "    elif clase == 1:\n",
        "      return divide(self.TNtl,(self.FNtl+self.TNtl))\n",
        "  \n",
        "  def recall_score(self,clase):\n",
        "    if clase == 0:\n",
        "      return divide(self.TP,(self.FN+self.FNtl+self.TP))\n",
        "    elif clase == 2:\n",
        "      return divide(self.TN,(self.FP+self.FNtl+self.TN))\n",
        "    elif clase == 1:\n",
        "      return divide(self.TNtl,(self.FN+self.FP+self.TNtl))\n",
        "\n",
        "  def accuracy_score(self):\n",
        "    return divide((self.TP+self.TN+self.TNtl),(self.TP+self.TN+self.FN+self.FP+self.FNtl+self.TNtl))\n",
        "\n",
        "  def f1_score(self,clase):\n",
        "    return divide(2*self.precision_score(clase)*self.recall_score(clase),(self.precision_score(clase)+self.recall_score(clase)))\n",
        "    \n",
        "  def roc_curve(self):\n",
        "    import numpy as np\n",
        "    import matplotlib.pyplot as plt\n",
        "    plt.style.use('ggplot')\n",
        "    plt.rcParams[\"figure.figsize\"] = (16,9)\n",
        "    %matplotlib inline\n",
        "\n",
        "    FPR = []\n",
        "    TPR = []\n",
        "\n",
        "    thresholds = np.arange(0.0, 1.01, 0.2)\n",
        "    for t in thresholds:\n",
        "      FP_ = 0\n",
        "      TP_ = 0\n",
        "      t = round(t,2)\n",
        "      for i in range(len(self.scores)):\n",
        "        if(self.scores[i][1] >= t):\n",
        "          if self.real[i] == 0:\n",
        "            TP_ += 1\n",
        "          if self.real[i] != 0:\n",
        "            FP_ += 1\n",
        "      FPR.append(divide(FP_,self.N))\n",
        "      TPR.append(divide(TP_,self.P))\n",
        "    \n",
        "    auc = -1 * np.trapz(TPR, FPR)\n",
        "\n",
        "    plt.plot(FPR, TPR, linestyle='--', marker='o', color='darkorange', lw = 2, label='ROC curve', clip_on=False)\n",
        "    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.0])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC curve, AUC = %.2f'%auc)\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.savefig(self.name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrF_3NwnddVU"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "def ensemble(redes, instancia, tipo):\n",
        "  moda = []\n",
        "  media = []\n",
        "\n",
        "  for red in redes:\n",
        "    args, mx = predict_query(red, instancia)\n",
        "    moda.append(mx[0])\n",
        "    media.append(args)\n",
        "  \n",
        "  c = Counter(moda)\n",
        "  \n",
        "  args_med = {}\n",
        "  for key in media[0].keys():\n",
        "    args_med[key] = 0\n",
        "\n",
        "  for elem in media:\n",
        "    for arg in elem:\n",
        "      args_med[arg]+= elem[arg]\n",
        "\n",
        "\n",
        "  for elem in args_med:\n",
        "    args_med[elem]/= len(redes)\n",
        "  \n",
        "  maxargs = [None, 0]\n",
        "  for x in args_med:\n",
        "    if(args_med[x] > maxargs[1]):\n",
        "      maxargs = [x,args_med[x]]\n",
        "  \n",
        "  \n",
        "  if(tipo == 'Moda'):\n",
        "    return [ c.most_common(1)[0][0] , args_med[c.most_common(1)[0][0]]] \n",
        "            \n",
        "  return maxargs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AlAVhwVsnXy"
      },
      "source": [
        "def predictEnsemble(redes, tipo, test):\n",
        "  data_test_Y = []\n",
        "  data_pred = []\n",
        "\n",
        "  for elem in test:\n",
        "    x = ensemble(redes, test, tipo)\n",
        "    data_test_Y.append(x)\n",
        "  \n",
        "  return data_pred, data_test_Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPRRPuTTwnM-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f30ba4c-5dfa-4568-d0d4-f15ef1c9595b"
      },
      "source": [
        "!pip install graphviz\n",
        "from graphviz import Digraph\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "import graphviz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (0.10.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eDIEy2-wG9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1ab180b690ca4eafa9b3b8e05fa2d18c",
            "9c7d70890a2447d0993703d613b1d29b",
            "de9b387ebe244dac91c370d25d5fec0b",
            "a3adc8013cb24078af65b8975d657dd9",
            "1c9f6f91ef864005b6b56669e2bb870e",
            "9282b0e939ea44708e7eb7ad9ca44235",
            "73453a384e294dcfb0486dee0aa231f5",
            "956554c74917443e89f06a343f98e2b5",
            "4dbf07f61bed47b695231f9408eac5da",
            "eb6e5cf4f8a147ee9067ce5729339122",
            "5962948827d14db486b90d28d648abe2",
            "173c2d7156914bdeb55e1cec36a6efb7",
            "3d6bc3b2f08f4df6aa5d955c79966e6c",
            "168e0a22ff5c4e6082f9a49470353e9b",
            "73683588e1a34288b4f80306cbc0057e",
            "a90a474d7dd14bb78f2762d9c73ec278",
            "a120817eb4c24ac0b54d9decf134184d",
            "e8f0d0ef466f4bc1bc8f1c5ca2530dc8"
          ]
        },
        "outputId": "2504de5a-8a4f-4047-e50b-2c02f9d7d230"
      },
      "source": [
        "tab_nest = widgets.Tab()\n",
        "\n",
        "loaded = False\n",
        "uploaded = False\n",
        "\n",
        "upl_data = widgets.FileUpload(accept='.xlsx',multiple=False,description=\"Select data.xlsx\")\n",
        "\n",
        "btn_upl_data = widgets.Button(\n",
        "    description='Upload DATASET',\n",
        "    disabled=False,\n",
        "    button_style='info', # 'success', 'info', 'warning', 'danger' or ''\n",
        "    tooltip='',\n",
        "    icon='check'\n",
        "    )\n",
        "\n",
        "input_limit = widgets.Text(\n",
        "    value='50',\n",
        "    placeholder='Cantidad a leer',\n",
        "    description='Cantidad a leer:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "btn_create = widgets.Button(\n",
        "    description='CREATE COMPONENTS',\n",
        "    disabled=False,\n",
        "    button_style='success', # 'success', 'info', 'warning', 'danger' or ''\n",
        "    tooltip='',\n",
        "    icon='check',\n",
        "    layout=widgets.Layout(width=\"17%\")\n",
        "    )\n",
        "\n",
        "def upl_data_file(a):\n",
        "  global uploaded\n",
        "  global upl_data\n",
        "  if upl_data.value == {}:\n",
        "    print(\"No hay ningun archivo subido.\")\n",
        "  else:\n",
        "    uploaded_filename = next(iter(upl_data.value))\n",
        "    content = upl_data.value[uploaded_filename]['content']\n",
        "    with open('data.xlsx', 'wb') as f: f.write(content)\n",
        "    uploaded = True\n",
        "    print(\"Archivo subido\")\n",
        "    upl_data.value.clear()\n",
        "    upl_data._counter = 0\n",
        "\n",
        "def load_components(a):\n",
        "    global uploaded\n",
        "    global db\n",
        "    global tab_nest\n",
        "    global input_limit\n",
        "\n",
        "    if uploaded == False:\n",
        "        print(\"Suba un archivo para crear los componentes\")\n",
        "        return\n",
        "\n",
        "    limit = int(input_limit.value)\n",
        "    \n",
        "    # SHOW DATAFRAME\n",
        "    n_i, names, df_names = readFile('data.xlsx', limit)\n",
        "    n_i, df_names = get_filtered_df(df_names, n_i)\n",
        "    df_names_len = len(df_names)\n",
        "    cut = int(df_names_len * 0.7)\n",
        "    train = df_names[0:cut]\n",
        "    test = df_names[cut:df_names_len]\n",
        "    print(\"Creando\")\n",
        "    db = bag_of_words(train)\n",
        "    print(\"Creado\")\n",
        "\n",
        "    rows_boxes = list()\n",
        "    labels=list()\n",
        "    for head in db.names:\n",
        "      label = widgets.Button(description = head, disabled = True, button_style='info')\n",
        "      labels.append(label)\n",
        "    headers_box = widgets.HBox(labels)\n",
        "\n",
        "    for row in db.df_names:\n",
        "      values=list()\n",
        "      for val in row:\n",
        "        value = widgets.Button(description = str(val), disabled = True)\n",
        "        values.append(value)\n",
        "      rows_boxes.append(widgets.HBox(values))\n",
        "    dataset_box = widgets.VBox([headers_box,*rows_boxes])\n",
        "\n",
        "    #GREEDY ENTROPIA\n",
        "    db_ge = greedyLS(db, 'Entropy')\n",
        "    metrics_ge = list()\n",
        "    graph_ge = list()\n",
        "\n",
        "    print(\"Predictions GE\")\n",
        "    ge_test_y, ge_data_pred = getPredicts(db_ge, test)\n",
        "    print(\"END GE\")\n",
        "    history_ge = metrics(ge_test_y,ge_data_pred,name=\"ge_roc.png\")\n",
        "    precision_ge = str(history_ge.precision_score(0))\n",
        "    recall_ge = str(history_ge.recall_score(0))\n",
        "    accuracy_ge = str(history_ge.accuracy_score())\n",
        "    f1_ge = str(history_ge.f1_score(0))\n",
        "    history_ge.roc_curve()\n",
        "\n",
        "    precison_ge_widget = widgets.Text(\n",
        "      value=precision_ge,\n",
        "      description='Precision:',\n",
        "      disabled=True\n",
        "    )\n",
        "\n",
        "    recall_ge_widget = widgets.Text(\n",
        "      value=recall_ge,\n",
        "      description='Recall:',\n",
        "      disabled=True\n",
        "    )\n",
        "        \n",
        "    accuracy_ge_widget = widgets.Text(\n",
        "      value=accuracy_ge,\n",
        "      description='Accuracy:',\n",
        "      disabled=True\n",
        "    )\n",
        "\n",
        "    f1_ge_widget = widgets.Text(\n",
        "      value=f1_ge,\n",
        "      description='Score:',\n",
        "      disabled=True\n",
        "    )\n",
        "\n",
        "    file_image_ge_roc = open(\"ge_roc.png\", \"rb\")\n",
        "    image_ge_roc = file_image_ge_roc.read()\n",
        "    image_widget_ge_roc = widgets.Image(value=image_ge_roc, format='png', layout=widgets.Layout(width='600px'))\n",
        "\n",
        "    metrics_ge.append(precison_ge_widget)\n",
        "    metrics_ge.append(recall_ge_widget)\n",
        "    metrics_ge.append(accuracy_ge_widget)\n",
        "    metrics_ge.append(f1_ge_widget)\n",
        "    metrics_ge.append(image_widget_ge_roc)\n",
        "    left_ge_vbox = widgets.VBox(metrics_ge)\n",
        "\n",
        "    dot_ge = Digraph(format='png')\n",
        "    for head in db_ge.names:\n",
        "      dot_ge.node(head)\n",
        "    for edge in db_ge.edges:\n",
        "      parent = edge[0] \n",
        "      child = edge[1]\n",
        "      dot_ge.edge(parent, child)\n",
        "    dot_ge.render(\"ge\")\n",
        "    file_image_ge = open(\"ge.png\", \"rb\")\n",
        "    image_ge = file_image_ge.read()\n",
        "    image_widget_ge = widgets.Image(value=image_ge, format='png', layout=widgets.Layout(width='1200px'))\n",
        "    graph_ge.append(image_widget_ge)\n",
        "    right_ge_vbox = widgets.VBox(graph_ge)\n",
        "    tab_ge = widgets.HBox([left_ge_vbox, right_ge_vbox])\n",
        "\n",
        "    #K2 ENTROPIA\n",
        "    db_ke = K2(db, 2, 5, 'Entropy')\n",
        "    metrics_ke = list()\n",
        "    graph_ke = list()\n",
        "\n",
        "    print(\"Predictions KE\")\n",
        "    ke_test_y, ke_data_pred = getPredicts(db_ke, test)\n",
        "    print(\"KE\")\n",
        "\n",
        "    history_ke = metrics(ke_test_y,ke_data_pred,name=\"ke_roc.png\")\n",
        "    precision_ke = str(history_ke.precision_score(0))\n",
        "    recall_ke = str(history_ke.recall_score(0))\n",
        "    accuracy_ke = str(history_ke.accuracy_score())\n",
        "    f1_ke = str(history_ke.f1_score(0))\n",
        "    history_ke.roc_curve()\n",
        "\n",
        "    precison_ke_widget = widgets.Text(\n",
        "      value=precision_ke,\n",
        "      description='Precision:',\n",
        "      disabled=True\n",
        "    )\n",
        "\n",
        "    recall_ke_widget = widgets.Text(\n",
        "      value=recall_ke,\n",
        "      description='Recall:',\n",
        "      disabled=True\n",
        "    )\n",
        "        \n",
        "    accuracy_ke_widget = widgets.Text(\n",
        "      value=accuracy_ke,\n",
        "      description='Accuracy:',\n",
        "      disabled=True\n",
        "    )\n",
        "\n",
        "    f1_ke_widget = widgets.Text(\n",
        "      value=f1_ke,\n",
        "      description='Score:',\n",
        "      disabled=True\n",
        "    )\n",
        "\n",
        "    file_image_ke_roc = open(\"ke_roc.png\", \"rb\")\n",
        "    image_ke_roc = file_image_ke_roc.read()\n",
        "    image_widget_ke_roc = widgets.Image(value=image_ke_roc, format='png', layout=widgets.Layout(width='600px'))\n",
        "\n",
        "    metrics_ke.append(precison_ke_widget)\n",
        "    metrics_ke.append(recall_ke_widget)\n",
        "    metrics_ke.append(accuracy_ke_widget)\n",
        "    metrics_ke.append(f1_ke_widget)\n",
        "    metrics_ke.append(image_widget_ke_roc)\n",
        "    left_ke_vbox = widgets.VBox(metrics_ke)\n",
        "\n",
        "    dot_ke = Digraph(format='png')\n",
        "    for head in db_ke.names:\n",
        "      dot_ke.node(head)\n",
        "    for edge in db_ke.edges:\n",
        "      parent = edge[0] \n",
        "      child = edge[1]\n",
        "      dot_ke.edge(parent, child)\n",
        "    dot_ke.render(\"ke\")\n",
        "    file_image_ke = open(\"ke.png\", \"rb\")\n",
        "    image_ke = file_image_ke.read()\n",
        "    image_widget_ke = widgets.Image(value=image_ke, format='png', layout=widgets.Layout(width='1200px'))\n",
        "    graph_ke.append(image_widget_ke)\n",
        "    right_ke_vbox = widgets.VBox(graph_ke)\n",
        "    tab_ke = widgets.HBox([left_ge_vbox, right_ke_vbox])\n",
        "\n",
        "    #GREEDY K2\n",
        "    db_gk = greedyLS(db, 'K2')\n",
        "    metrics_gk = list()\n",
        "    graph_gk = list()\n",
        "\n",
        "    print(\"Predictions GK\")\n",
        "    gk_test_y, gk_data_pred = getPredicts(db_gk, test)\n",
        "    print(\"END GK\")\n",
        "\n",
        "    history_gk = metrics(gk_test_y,gk_data_pred,name=\"gk_roc.png\")\n",
        "    precision_gk = str(history_gk.precision_score(0))\n",
        "    recall_gk = str(history_gk.recall_score(0))\n",
        "    accuracy_gk = str(history_gk.accuracy_score())\n",
        "    f1_gk = str(history_gk.f1_score(0))\n",
        "    history_gk.roc_curve()\n",
        "\n",
        "    precison_gk_widget = widgets.Text(\n",
        "      value=precision_gk,\n",
        "      description='Precision:',\n",
        "      disabled=True\n",
        "    )\n",
        "\n",
        "    recall_gk_widget = widgets.Text(\n",
        "      value=recall_gk,\n",
        "      description='Recall:',\n",
        "      disabled=True\n",
        "    )\n",
        "        \n",
        "    accuracy_gk_widget = widgets.Text(\n",
        "      value=accuracy_gk,\n",
        "      description='Accuracy:',\n",
        "      disabled=True\n",
        "    )\n",
        "\n",
        "    f1_gk_widget = widgets.Text(\n",
        "      value=f1_gk,\n",
        "      description='Score:',\n",
        "      disabled=True\n",
        "    )\n",
        "\n",
        "    file_image_gk_roc = open(\"gk_roc.png\", \"rb\")\n",
        "    image_gk_roc = file_image_gk_roc.read()\n",
        "    image_widget_gk_roc = widgets.Image(value=image_gk_roc, format='png', layout=widgets.Layout(width='600px'))\n",
        "\n",
        "    metrics_gk.append(precison_gk_widget)\n",
        "    metrics_gk.append(recall_gk_widget)\n",
        "    metrics_gk.append(accuracy_gk_widget)\n",
        "    metrics_gk.append(f1_gk_widget)\n",
        "    metrics_gk.append(image_widget_gk_roc)\n",
        "    left_gk_vbox = widgets.VBox(metrics_gk)\n",
        "\n",
        "    dot_gk = Digraph(format='png')\n",
        "    for head in db_gk.names:\n",
        "      dot_gk.node(head)\n",
        "    for edge in db_gk.edges:\n",
        "      parent = edge[0] \n",
        "      child = edge[1]\n",
        "      dot_gk.edge(parent, child)\n",
        "    dot_gk.render(\"gk\")\n",
        "    file_image_gk = open(\"gk.png\", \"rb\")\n",
        "    image_gk = file_image_gk.read()\n",
        "    image_widget_gk = widgets.Image(value=image_gk, format='png', layout=widgets.Layout(width='1200px'))\n",
        "    graph_gk.append(image_widget_gk)\n",
        "    right_gk_vbox = widgets.VBox(graph_gk)\n",
        "    tab_gk = widgets.HBox([left_ge_vbox, right_gk_vbox])\n",
        "\n",
        "    #K2 K2\n",
        "    db_kk = K2(db, 2, 5, 'K2')\n",
        "    metrics_kk = list()\n",
        "    graph_kk = list()\n",
        "\n",
        "    print(\"Predictions KK\")\n",
        "    kk_test_y, kk_data_pred = getPredicts(db_kk, test)\n",
        "    print(\"END KK\")\n",
        "\n",
        "    history_kk = metrics(kk_test_y,kk_data_pred,name=\"kk_roc.png\")\n",
        "    precision_kk = str(history_kk.precision_score(0))\n",
        "    recall_kk = str(history_kk.recall_score(0))\n",
        "    accuracy_kk = str(history_kk.accuracy_score())\n",
        "    f1_kk = str(history_kk.f1_score(0))\n",
        "    history_kk.roc_curve()\n",
        "\n",
        "    precison_kk_widget = widgets.Text(\n",
        "      value=precision_kk,\n",
        "      description='Precision:',\n",
        "      disabled=True\n",
        "    )\n",
        "\n",
        "    recall_kk_widget = widgets.Text(\n",
        "      value=recall_kk,\n",
        "      description='Recall:',\n",
        "      disabled=True\n",
        "    )\n",
        "        \n",
        "    accuracy_kk_widget = widgets.Text(\n",
        "      value=accuracy_kk,\n",
        "      description='Accuracy:',\n",
        "      disabled=True\n",
        "    )\n",
        "\n",
        "    f1_kk_widget = widgets.Text(\n",
        "      value=f1_kk,\n",
        "      description='Score:',\n",
        "      disabled=True\n",
        "    )\n",
        "\n",
        "    file_image_kk_roc = open(\"kk_roc.png\", \"rb\")\n",
        "    image_kk_roc = file_image_kk_roc.read()\n",
        "    image_widget_kk_roc = widgets.Image(value=image_kk_roc, format='png', layout=widgets.Layout(width='600px'))\n",
        "\n",
        "    metrics_kk.append(precison_kk_widget)\n",
        "    metrics_kk.append(recall_kk_widget)\n",
        "    metrics_kk.append(accuracy_kk_widget)\n",
        "    metrics_kk.append(f1_kk_widget)\n",
        "    metrics_kk.append(image_widget_kk_roc)\n",
        "    left_kk_vbox = widgets.VBox(metrics_kk)\n",
        "\n",
        "    dot_kk = Digraph(format='png')\n",
        "    for head in db_kk.names:\n",
        "      dot_kk.node(head)\n",
        "    for edge in db_kk.edges:\n",
        "      parent = edge[0] \n",
        "      child = edge[1]\n",
        "      dot_kk.edge(parent, child)\n",
        "    dot_kk.render(\"kk\")\n",
        "    file_image_kk = open(\"kk.png\", \"rb\")\n",
        "    image_kk = file_image_kk.read()\n",
        "    image_widget_kk = widgets.Image(value=image_kk, format='png', layout=widgets.Layout(width='1200px'))\n",
        "    graph_kk.append(image_widget_kk)\n",
        "    right_kk_vbox = widgets.VBox(graph_kk)\n",
        "    tab_kk = widgets.HBox([left_ge_vbox, right_kk_vbox])\n",
        "\n",
        "    redes = [db_ge, db_ke, db_gk, db_kk]\n",
        "\n",
        "    #E M\n",
        "    metrics_em = list()\n",
        "\n",
        "    print(\"Predictions EM\")\n",
        "    em_test_y, em_data_pred = predictEnsemble(redes,'Moda',test)\n",
        "    print(\"END EM\")\n",
        "\n",
        "    history_em = metrics(em_test_y,em_data_pred,name=\"em_roc.png\")\n",
        "    precision_em = str(history_em.precision_score(0))\n",
        "    recall_em = str(history_em.recall_score(0))\n",
        "    accuracy_em = str(history_em.accuracy_score())\n",
        "    f1_em = str(history_em.f1_score(0))\n",
        "\n",
        "    precison_em_widget = widgets.Text(\n",
        "      value=precision_em,\n",
        "      description='Precision:',\n",
        "      disabled=True\n",
        "    )\n",
        "\n",
        "    recall_em_widget = widgets.Text(\n",
        "      value=recall_em,\n",
        "      description='Recall:',\n",
        "      disabled=True\n",
        "    )\n",
        "        \n",
        "    accuracy_em_widget = widgets.Text(\n",
        "      value=accuracy_em,\n",
        "      description='Accuracy:',\n",
        "      disabled=True\n",
        "    )\n",
        "\n",
        "    f1_em_widget = widgets.Text(\n",
        "      value=f1_em,\n",
        "      description='Score:',\n",
        "      disabled=True\n",
        "    )\n",
        "\n",
        "    metrics_em.append(precison_em_widget)\n",
        "    metrics_em.append(recall_em_widget)\n",
        "    metrics_em.append(accuracy_em_widget)\n",
        "    metrics_em.append(f1_em_widget)\n",
        "    left_em_vbox = widgets.VBox(metrics_em)\n",
        "\n",
        "    right_em_vbox = widgets.VBox()\n",
        "    tab_em = widgets.HBox([left_ge_vbox, right_em_vbox])   \n",
        "\n",
        "        #E M\n",
        "    metrics_em = list()\n",
        "\n",
        "    print(\"Predictions EM\")\n",
        "    em_test_y, em_data_pred = predictEnsemble(redes,'Media',test)\n",
        "    print(\"END EM\")\n",
        "\n",
        "    history_em = metrics(em_test_y,em_data_pred,name=\"em_roc.png\")\n",
        "    precision_em = str(history_em.precision_score(0))\n",
        "    recall_em = str(history_em.recall_score(0))\n",
        "    accuracy_em = str(history_em.accuracy_score())\n",
        "    f1_em = str(history_em.f1_score(0))\n",
        "\n",
        "    precison_em_widget = widgets.Text(\n",
        "      value=precision_em,\n",
        "      description='Precision:',\n",
        "      disabled=True\n",
        "    )\n",
        "\n",
        "    recall_em_widget = widgets.Text(\n",
        "      value=recall_em,\n",
        "      description='Recall:',\n",
        "      disabled=True\n",
        "    )\n",
        "        \n",
        "    accuracy_em_widget = widgets.Text(\n",
        "      value=accuracy_em,\n",
        "      description='Accuracy:',\n",
        "      disabled=True\n",
        "    )\n",
        "\n",
        "    f1_em_widget = widgets.Text(\n",
        "      value=f1_em,\n",
        "      description='Score:',\n",
        "      disabled=True\n",
        "    )\n",
        "\n",
        "    metrics_em.append(precison_em_widget)\n",
        "    metrics_em.append(recall_em_widget)\n",
        "    metrics_em.append(accuracy_em_widget)\n",
        "    metrics_em.append(f1_em_widget)\n",
        "    left_em_vbox = widgets.VBox(metrics_em)\n",
        "\n",
        "    right_em_vbox = widgets.VBox()\n",
        "    tab_ex = widgets.HBox([left_ge_vbox, right_em_vbox])   \n",
        "\n",
        "    tab_nest.children = [*tab_nest.children,dataset_box,tab_ge,tab_ke,tab_gk,tab_kk,tab_em,tab_ex]\n",
        "\n",
        "btn_upl_data.on_click(upl_data_file)\n",
        "btn_create.on_click(load_components)\n",
        "\n",
        "upl_data_box = widgets.HBox([upl_data,btn_upl_data, input_limit])\n",
        "upl_box = widgets.VBox([upl_data_box,btn_create])\n",
        "\n",
        "tab_nest.children = [upl_box]\n",
        "tab_nest.set_title(0, 'UPLOAD')\n",
        "tab_nest.set_title(1, 'DATASET')\n",
        "tab_nest.set_title(2, 'GREEDY/ENTROPIA')\n",
        "tab_nest.set_title(3, 'K2/ENTROPIA')\n",
        "tab_nest.set_title(4, 'GREEDY/K2')\n",
        "tab_nest.set_title(5, 'K2/K2')\n",
        "tab_nest.set_title(6, 'MODA/ENSAMBLE')\n",
        "tab_nest.set_title(6, 'MAX/ENSAMBLE')\n",
        "tab_nest"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ab180b690ca4eafa9b3b8e05fa2d18c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Tab(children=(VBox(children=(HBox(children=(FileUpload(value={}, accept='.xlsx', description='Select data.xlsx…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Archivo subido\n",
            "['administracion', 'hermano', 'nosotras', 'tambien', 'robaron', 'deberian', 'opcion', 'sus', 'eliminen', 'injusto', 'ciclo', 'wapaax', 'siento', 'estamos', 'robotico', 'verlas', 'trabajo', 'gordita', 'como', 'ps', 'esperamos', 'seria', 'pre', 'fechas', 'capo', 'sera', 'muchas', 'tarde', 'colaboradores', 'pagina', 'excelente', 'soy', 'mundo', 'v', 'esta', 'solo', 'caso', 'todas', 'puedes', 'salgo', 'sentimos', 'y', 'invento', 'wow', 'espectacular', 'pasando', 'acercarte', 'visto', 'tu', '', 'son', 'pero', 'ustedes', 'este', 'tendran', 'acreditar', 'tremendo', 'publiquen', 'eres', 'al', 'orgulloupn', 'danza', 'tener', 'salieron', 'mal', 'profesionales', 'siga', 'el', 'gran', 'manita', 'seguro', 'upc', 'alexis', 'ahora', 'elenco', 'etiquetenlas', 'gracias', 'carreras', 'cuando', 'sabes', 'inscripcion', 'pruebas', 'mas', 'universidad', 'si', 'vvv', 'genial', 'me', 'upn', 'ti', 'burlados', 'por', 'pago', 'que', 'la', 'fecha', 'virtuales', 'sean', 'campus', 'conscientes', 'eow', 'ya', 'u', 'vender', 'futuro', 'jajaja', 'genio', 'educacion', 'derecho', 'veo', 'a', 'para', 'cada', 'cuarentena', 'tmb', 'no', 'venderan', 'los', 'trujillo', 'coordinador', 'felicidades', 'mi', 'genioooo', 'respeto', 'fotografias', 'de', 'vida', 'muchos', 'tenemos', 'mira', 'antiguo', 'nos', 'parte', 'respuesta', 'primera', 'nuestros', 'hasta', 'seleccion', 'alumnos', 'judo', 'acreditacion', 'vendida', 'hay', 'vamos', 'ingresos', 'es', 'hermosas', 'oficina', 'voley', 'triunfo', 'un', 'convocatoria', 'representa', 'partir', 'nuestras', 'mejor', 'aumentamdo', 'escogi', 'fotos', 'juegan', 'graduados', 'van', 'habia', 'tecnicas', 'pongan', 'felicitaciones', 'en', 'todo', 'inicio', 'brazo', 'crack', 'indignacion', 'una', 'las', 'lo', 'ne', 'irrisorias', 'te', 'trabajan', 'pe', 'universitaria', 'algunos', 'señores', 'graduandos', 'pension']\n",
            "-315\n",
            "Creando\n",
            "Creado\n",
            "Predictions GE\n",
            "cuarentena injusto pongan fechas pago y tendran ingresos conscientes mundo pasando \n",
            "['cuarentena', 'injusto', 'pongan', 'fechas', 'pago', 'y', 'tendran', 'ingresos', 'conscientes', 'mundo', 'pasando']\n",
            "publiquen juegan a verlas\n",
            "['publiquen', 'juegan', 'a', 'verlas']\n",
            "-----------------\n",
            "maxargs:  [0, 0.0441175]\n",
            "graduandos \n",
            "['graduandos']\n",
            "brazo robotico invento antiguo \n",
            "['brazo', 'robotico', 'invento', 'antiguo']\n",
            "ps manita robaron triunfo \n",
            "['ps', 'manita', 'robaron', 'triunfo']\n",
            "señores upn respeto alumnos alumnos derecho sentimos burlados fecha coordinador y respuesta colaboradores u irrisorias\n",
            "['señores', 'upn', 'respeto', 'alumnos', 'alumnos', 'derecho', 'sentimos', 'burlados', 'fecha', 'coordinador', 'y', 'respuesta', 'colaboradores', 'u', 'irrisorias']\n",
            "y pension siga aumentamdo \n",
            "['y', 'pension', 'siga', 'aumentamdo']\n",
            "upn vendida \n",
            "['upn', 'vendida']\n",
            "deberian acreditar carreras\n",
            "['deberian', 'acreditar', 'carreras']\n",
            "-----------------\n",
            "maxargs:  [0, 0.00259516782]\n",
            "venderan \n",
            "['venderan']\n",
            "y acreditacion carreras \n",
            "['y', 'acreditacion', 'carreras']\n",
            "-----------------\n",
            "maxargs:  [0, 0.0441175]\n",
            "a vender \n",
            "['a', 'vender']\n",
            "-----------------\n",
            "maxargs:  [0, 0.0441175]\n",
            "eliminen virtuales\n",
            "['eliminen', 'virtuales']\n",
            "escogi opcion educacion y siento indignacion \n",
            "['escogi', 'opcion', 'educacion', 'y', 'siento', 'indignacion']\n",
            "upc ne representa\n",
            "['upc', 'ne', 'representa']\n",
            "END GE\n",
            "Predictions KE\n",
            "cuarentena injusto pongan fechas pago y tendran ingresos conscientes mundo pasando \n",
            "['cuarentena', 'injusto', 'pongan', 'fechas', 'pago', 'y', 'tendran', 'ingresos', 'conscientes', 'mundo', 'pasando']\n",
            "publiquen juegan a verlas\n",
            "['publiquen', 'juegan', 'a', 'verlas']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYasqtRfGAk_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}